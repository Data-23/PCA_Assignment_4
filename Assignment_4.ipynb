{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75290413",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Step 1: Load the dataset\n",
    "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data'\n",
    "columns = ['Alcohol', 'Malic acid', 'Ash', 'Alcalinity of ash', 'Magnesium',\n",
    "           'Total phenols', 'Flavanoids', 'Nonflavanoid phenols', 'Proanthocyanins',\n",
    "           'Color intensity', 'Hue', 'OD280/OD315 of diluted wines', 'Proline']\n",
    "\n",
    "data = pd.read_csv(url, header=None, names=['Target'] + columns)\n",
    "print(data.head())\n",
    "\n",
    "# Step 2: Split the dataset into features and target variables\n",
    "X = data.drop('Target', axis=1)\n",
    "y = data['Target']\n",
    "\n",
    "# Step 3: Data preprocessing\n",
    "# Scaling the data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Step 4: Implement PCA\n",
    "pca = PCA()\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "# Determine the optimal number of principal components to retain\n",
    "explained_variance = np.cumsum(pca.explained_variance_ratio_)\n",
    "optimal_components = np.argmax(explained_variance >= 0.95) + 1\n",
    "\n",
    "print(f\"Optimal number of components to retain: {optimal_components}\")\n",
    "\n",
    "# Plot the explained variance ratio\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.plot(range(1, len(explained_variance) + 1), explained_variance, marker='o', linestyle='--')\n",
    "plt.xlabel('Number of Components')\n",
    "plt.ylabel('Cumulative Explained Variance')\n",
    "plt.title('Explained Variance by Principal Components')\n",
    "plt.axvline(x=optimal_components, color='r', linestyle='--')\n",
    "plt.show()\n",
    "\n",
    "# Retain optimal number of principal components\n",
    "pca = PCA(n_components=optimal_components)\n",
    "X_pca_optimal = pca.fit_transform(X_scaled)\n",
    "\n",
    "# Step 5: Visualize PCA results\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.scatter(X_pca_optimal[:, 0], X_pca_optimal[:, 1], c=y, cmap='viridis', edgecolor='k', s=100)\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.title('PCA Result: Wine Dataset')\n",
    "plt.colorbar(label='Target')\n",
    "plt.show()\n",
    "\n",
    "# Step 6: Perform clustering on the PCA-transformed data using K-Means\n",
    "kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "clusters = kmeans.fit_predict(X_pca_optimal)\n",
    "\n",
    "# Visualize the clusters\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.scatter(X_pca_optimal[:, 0], X_pca_optimal[:, 1], c=clusters, cmap='viridis', edgecolor='k', s=100)\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.title('K-Means Clustering on PCA-Transformed Data')\n",
    "plt.colorbar(label='Cluster')\n",
    "plt.show()\n",
    "\n",
    "# Step 7: Interpretation\n",
    "print(\"Explained Variance Ratio by Principal Components:\")\n",
    "print(pca.explained_variance_ratio_)\n",
    "\n",
    "print(\"\\nK-Means Clustering Performance:\")\n",
    "print(f\"Inertia: {kmeans.inertia_}\")\n",
    "print(f\"Cluster Centers: {kmeans.cluster_centers_}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
